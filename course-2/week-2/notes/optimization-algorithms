-- Mini-batch Gradient Descent --

In deep learning with ~5,000,000+ training examples, training this enormous amount of data for every step of gradient descent is computationally expensive.

-One way you can solve this is splitting training sets (X & Y) into 5,000 tiny subsets of 1,000 examples each ( x^{1} = [x(1),x(2),...x(1000)] , ... , x^{5000} )

x^(i) = i'th training example
x^[l] = l'th layer
x^{t} = t'th mini-batch

X^{i} is (nx, 1000)
Y^{i} is (1, 1000)

for t = 1, ... , 5000
	[one step of gradient descent using X^{t}, Y^{t}]
	Forward prop on X^{t}  (vectorized for 1000 examples)
		Z[1] = W[1]X{t} + b[1]
		A[1] = g[1](Z[1])
		...
		A[L] = g[L](Z[L])
	Compute cost function J = 1/1000 * sum([loss function(yhat, y)]) + lambda/2000 * sum(np.linalg.norm(W)^2)
	Backprop to compute gradients wrt J{t} (using X{t}, Y{t})
	W[l] = W[l] - alpha * dW[l], b[l] = b[l] - alpha * db[l]

!With every pass through the training set (5 mil examples)
	-Batch: 1 step of gradient descent
	-Mini-batch: 5,000 steps of gradient descent

===============================================================================
-- Understanding Mini-batch Gradient Descent --

When plotting cost function over # of iterations:
	-Batch: always decreases
	-Mini-batch: noisier but trends toward decreasing cost

Minibatch size of:
	m ==> batch gradient descent
	1 ==> stochastic gradient descent

!In practice, somewhere between 1 and m
	-If too large:
		-Too long to calculate every iteration (assuming large training set)
	-If too small:
		-Lose speedup from vectorization (every training example processed)
	!-In between:
		-Vectorized (~1000)
		-Progress without processing entire set

?How to choose where between 1 and m?
	-If small training set (m < 2000):
		-Use batch gradient descent
	-Otherwise:
		-Minibatch sizes of:
			-64, 128, 256, 512; 1024?
	-Make sure minibatch fits in CPU/GPU memory

===============================================================================
-- Exponentially Weighted Averages --

Vt = beta * V(t-1) + (1 - beta) * Thetat

~= 1 / (1 - beta) day's temperature
	- 0.9 ==> average over last 10 days
	- 0.98 ==> average over last 50 days
	- 0.5 ==> average over last 2 days
	*- Beta is how much weight is given to average over previous days

===============================================================================
-- Understanding Exponentially Weighted Averages --

(1 - epsilon) ^ (1 / epsilon) ~= 1/e

*Averages over a data set attributed with a decaying exponential value over time (the faster the decay, the higher the recency bias)

Implementation:
	V := 0
	V := beta*V + (1-beta)*theta1
	V := beta*V + (1-beta)*theta2
  -------------
	V = 0
	Repeat:
		Get next theta
		V := beta*V + (1-beta)*theta

!The advantage of this is that it is *very* computationally efficient, even if it is not the most accurate average

===============================================================================
-- Bias Correction in Exponentially Weighted Averages --

When initialized as 0, an exponentially weighted average will start lower than usual and "catch up" later. 

!So all that is needed to correct for this is divide by a "bias correction" constant that decays over time.

V = [formula] / (1 - beta^t)
	-When t is large, this term is negligible; but large at the start to compensate for lack of data

===============================================================================
-- Gradient Descent with Momentum --



===============================================================================
-- RMSprop --



===============================================================================
-- Adam Optimization Algorithm --



===============================================================================
-- Learning Rate Decay --



===============================================================================
-- The Problem of Local Optima --



===============================================================================
